{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ac7916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from fpdf import FPDF\n",
    "from contextlib import redirect_stdout\n",
    "# from reportlab.pdfgen.canvas import Canvas\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#remove the measurements\n",
    "import unicodedata\n",
    "unicodedata.numeric(u'⅕')\n",
    "unicodedata.name(u'⅕')\n",
    "import spacy\n",
    "import re\n",
    "# pip install spacy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dfa3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting coding\n",
    "\n",
    "# 1st function - User inputs the ingredients he has (or wants to use)\n",
    "def get_existing_ingredients():\n",
    "    ingredients = input(\"Input the ingredients you choosed, separated by ',': \")\n",
    "    list_confirmation = input('Is your the list ready? please confirm (Yes/No): ')\n",
    "    print('\\n')\n",
    "    list_confirmation = list_confirmation.lower()\n",
    "    if list_confirmation == \"yes\" or list_confirmation == \"y\":\n",
    "        get_recipes(ingredients)\n",
    "    else:\n",
    "        get_existing_ingredients()\n",
    "\n",
    "\n",
    "# 2nd step - Code will search at the url the recipes containing the inputted ingredients\n",
    "def get_recipes(ingredients):\n",
    "    url = \"https://edamam-recipe-search.p.rapidapi.com/search\"\n",
    "    querystring = {\"q\":ingredients}\n",
    "    headers = {\n",
    "    \"X-RapidAPI-Key\": \"636e6bafbemsh4d60f9770bbe76cp1e897ejsn1e8e8c2c9a8c\",\n",
    "    \"X-RapidAPI-Host\": \"edamam-recipe-search.p.rapidapi.com\"\n",
    "    }\n",
    "    \n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "\n",
    "    #data is always given for a total of 10 recipes\n",
    "    recipe_data = pd.json_normalize(response.json()['hits'])\n",
    "    recipe_data1 = recipe_data.rename(columns={'recipe.ingredientLines' : 'ingridient'})\n",
    "\n",
    "    #Put each ingredient in a row, duplicating the recipe rows\n",
    "    df = recipe_data1.explode('ingridient')\n",
    "\n",
    "    #splits the words, tokenizes them and assigns them a role, then a search is made for the searched roles\n",
    "    base_model = spacy.load('en_core_web_sm')\n",
    "\n",
    "    measurements = re.compile(r'(enough|sliced|Sliced|halves|Halves|quart|pure|raw|unsweetened|Flaky|extra|Extra|fresh|fresh|juice|Juice|clear|½|weight|Small|small|tub|Tablespoon|lb|homemade|bowl|g|C|Tablespoons|1|2|3|4|5|6|7|8|9|0|medium|Medium|¼|Extra Virgin|slices|kg|100ml|200m|qts|lqts|lbs|tsp|tbs|Tbs|tbsp|bulb|cube|clove|cup|drop|ounce|oz|pinch|pound|teaspoon|large|grams|whole|tablespoon)s?')\n",
    "    extracted = []\n",
    "\n",
    "    for ix, row in df.iterrows():\n",
    "    #     print('\\r', \"Extracting ingredient for row\", ix, end='')\n",
    "        tokens = base_model(row['ingridient'])\n",
    "        extract = ''\n",
    "        for token in tokens:\n",
    "            if (token.dep_ in ['nsubj', 'ROOT']) and (token.pos_ in ['NOUN', 'PROPN']) and (not measurements.match(token.text)):\n",
    "            #explore children\n",
    "                for child in token.children:\n",
    "                    if (not measurements.match(child.text)) and (child.dep_ in ['amod', 'compound']):\n",
    "                        extract += child.text + ' '\n",
    "                extract += token.text + ' '\n",
    "        extracted.append(extract) \n",
    "\n",
    "    extracted_clean = []\n",
    "\n",
    "    for item in extracted:\n",
    "        item1 = item.strip()    \n",
    "        extracted_clean.append(item1)\n",
    "\n",
    "    #convert to dataframe to view and cleaning info\n",
    "    clean_recipe = df[['recipe.label', 'recipe.url', 'recipe.healthLabels', 'recipe.calories', 'recipe.totalTime','recipe.mealType']]\n",
    "    clean_recipe['ingredient'] = extracted_clean\n",
    "    nan_value = float(\"NaN\")\n",
    "    clean_recipe.replace(\"\", nan_value, inplace=True)\n",
    "    clean_recipe.dropna(subset = [\"ingredient\"], inplace=True)\n",
    " \n",
    "   \n",
    "    # Let's show only the shorter recipes (less ingredients missing) and sort by smaller\n",
    "    shorter_dict = {}\n",
    "    for x in range(0,9):\n",
    "        clean_recipe_x = clean_recipe.loc[x]\n",
    "        list_recipe_x = list(clean_recipe_x['ingredient'])\n",
    "        shorter_dict[x] = len(list_recipe_x)\n",
    "    shorter_dict = (dict(sorted(shorter_dict.items(), key=lambda item: item[1])))\n",
    "    shorter_list = list(shorter_dict.keys())\n",
    "    \n",
    "    # remove the ingredientes that we have from the list\n",
    "    list_imput = ingredients.split(\",\")\n",
    "    for list_imput in list_imput:\n",
    "        shopping_list = [ingredient for ingredient in list_recipe_x if list_imput not in ingredient]\n",
    "    \n",
    "    \n",
    "    #     Here is were we set 3 recipes from 9 as feeedback (the 3 most shorter)\n",
    "    shorter_list = shorter_list[0:3]\n",
    "    get_ingredient_detail(shorter_list, clean_recipe, ingredients)\n",
    "\n",
    "    \n",
    "# 3rd step - At this point we have the initial ingredients and the recipes including them\n",
    "# On this step we will call the function that does web-scrapping of the missing ingredients\n",
    "def get_ingredient_detail(shorter_list, clean_recipe, ingredients):\n",
    "    for x in range(0,3):\n",
    "        clean_recipe_x = clean_recipe.loc[shorter_list[x]]\n",
    "        list_recipe_x = list(clean_recipe_x['ingredient'])\n",
    "        list_imput = ingredients.split(\",\")\n",
    "        for list_imput in list_imput:\n",
    "            shopping_list = [ingredient for ingredient in list_recipe_x if list_imput not in ingredient]\n",
    "    \n",
    "        print('\\n')\n",
    "        print(\"RECIPE No\",x+1,'-', (clean_recipe ['recipe.label'][x]).unique())\n",
    "        print('-------------')\n",
    "        print('\\n','- Existing Ingredients       : ', ingredients) \n",
    "        print(' - Missing Ingredients (',len(shopping_list),')  : ', (', '.join(shopping_list)))\n",
    "        print(' - Cooking Time (minutes)     : ', (clean_recipe ['recipe.totalTime'][x]).mean())\n",
    "        print(' - Recipe Calories (1 portion): ', (clean_recipe ['recipe.calories'][x]).unique())\n",
    "        print(' - Cooking Instructions       : ', (clean_recipe ['recipe.url'][x]).unique())\n",
    "        missing_ingredients(shopping_list)\n",
    "        you_want_copy(shopping_list, x, clean_recipe, ingredients)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b26a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4rd step - This is the function that web-scrap the missing ingredients and show results\n",
    "def missing_ingredients(list_of_ingredients):\n",
    "    list_of_ingredients = [item.lower() for item in list_of_ingredients]\n",
    "    order = 0\n",
    "    print('\\n', 'GROCERY LIST')\n",
    "    for ingredient in list_of_ingredients:\n",
    "        \n",
    "        #         Initializating variables\n",
    "        order = order+1\n",
    "        url = \"https://www.abelandcole.co.uk/shop/search?term=\"+ingredient+\"&searchCat=products\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content)\n",
    "\n",
    "        #         Searching for ingredient name at the web\n",
    "        name_search = soup.find_all(\"div\", attrs={'class':'product-title'}) \n",
    "        name = [(option.text).replace('\\n', '') for option in name_search]\n",
    "\n",
    "        #         Searching for ingredient price at the web\n",
    "        price_search = soup.find_all(\"div\", attrs={'class':'product-price'})\n",
    "        price = [(option.text).replace('\\n', '').replace('\\r', '').replace(' ', '').replace('£', '    £') for option in price_search]\n",
    "\n",
    "        final_list = []\n",
    "        \n",
    "        #         Appending name+price as single list element\n",
    "        for i in range(len(name)):\n",
    "            final_list.append(name[i]+' '+price[i])\n",
    "\n",
    "        #         Showing results or error message\n",
    "        if not final_list:\n",
    "            print('\\n', str(order)+\".\"+ingredient.upper())\n",
    "            \n",
    "        #             Calling the 2nd function to search \n",
    "            single_ingredient(ingredient)\n",
    "        else:\n",
    "            print('\\n', str(order)+\".\"+ingredient.upper())\n",
    "            print('\\n'.join(final_list[:2]))\n",
    "    \n",
    "    print('\\n')\n",
    "    print('================================================================================')\n",
    "    print('Usual Supplier (unless different is indicated) is: https://www.abelandcole.co.uk')\n",
    "    print('Considerations for usual Supplier:','\\n','     - Price without taxes','\\n','     - if there is a 2nd price detailed consider as \"offert\"')\n",
    "\n",
    "\n",
    "# 5th step - on each recipe iteration (where we search missing ingredientes) code asks user if wants a .pdf copy\n",
    "def you_want_copy(shopping_list, x, clean_recipe, ingredients):    \n",
    "    #     Checking if user wants a copy file with info\n",
    "    print('================================================================================')\n",
    "    create_file = input(\"Would you like to create a '.pdf' file with this info? (Yes/No):\")\n",
    "    create_file = create_file.lower()\n",
    "    if create_file == \"yes\" or create_file == \"y\":\n",
    "        print(\"Preparing '.pdf' file..............\")\n",
    "        create_results_files(shopping_list, x, clean_recipe, ingredients)\n",
    "        txt_file_name = str(x+1)+'.txt'\n",
    "        os.remove(txt_file_name)\n",
    "        print('YOUR FILE IS READY, HAVE A NICE DAY!')\n",
    "        print('================================================================================')\n",
    "    else:\n",
    "        print('NO FILE WAS CREATED, HAVE A NICE DAY!')\n",
    "        print('================================================================================')\n",
    "\n",
    "        \n",
    "\n",
    "# This is a sub-function from step 4, doing web-scrapping in a 2nd webpage \n",
    "# just in case 1st one doesn't include the ingredient    \n",
    "def single_ingredient(ingredient):\n",
    "    ingredient = ingredient.lower()\n",
    "    url = \"https://www.dutchexpatshop.com/en/catalogsearch/result/?q=\"+ingredient\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content)\n",
    "    \n",
    "    search = soup.find_all(\"div\", attrs={'class':'product-item-info'})\n",
    "    list = [option.text for option in search]\n",
    "    list1 = [info.replace('        Add to Cart ', '') for info in list]\n",
    "    \n",
    "    if not list1:\n",
    "        print(\" Sorry, couldn't find this ingredient, please check and try again\",'\\n', \"We tried in this 2 webpages: www.abelandcole.co.uk & www.dutchexpatshop.com\")\n",
    "    else:\n",
    "        print('\\n'.join(list1[:2]))\n",
    "        print(\"** This specific product was found at: www.dutchexpatshop.com - Price with and without tax\")   \n",
    "\n",
    "        \n",
    "# This is a sub-function from step 5, if users do wants a .pdf copy of the recipe\n",
    "# The code will create a .txt file first and then will convert to .pdf (erasing original .txt)      \n",
    "def create_results_files(shopping_list, x, clean_recipe, ingredients):\n",
    "    # 1st create the txt result file     \n",
    "    txt_file_name = str(x+1)+'.txt'\n",
    "    with open(txt_file_name, 'w') as file:\n",
    "        with redirect_stdout(file):\n",
    "            output = print(\"RECIPE No\",x+1,'-', (clean_recipe ['recipe.label'][x]).unique())\n",
    "            output = print('-------------')\n",
    "            output = print('\\n','- Existing Ingredients       : ', ingredients)\n",
    "            output = print(' - Missing Ingredients (',len(shopping_list),')  : ', (', '.join(shopping_list))) \n",
    "            output = print(' - Cooking Time (minutes)     : ', (clean_recipe ['recipe.totalTime'][x]).mean())\n",
    "            output = print(' - Recipe Calories (1 portion): ', (clean_recipe ['recipe.calories'][x]).unique())\n",
    "            output = print(' - Cooking Instructions       : ', (clean_recipe ['recipe.url'][x]).unique())\n",
    "            output = str(missing_ingredients(shopping_list))    \n",
    "    \n",
    "    # 2nd convert txt result file into pdf  \n",
    "    pdf_file_name = str(x+1)+'.pdf'\n",
    "    with open(txt_file_name,'rb') as research:\n",
    "        pdf = FPDF()\n",
    "        pdf.add_page()\n",
    "        pdf.set_font('arial', size=10)\n",
    "        for line in research:\n",
    "            info = line.decode('latin-1')\n",
    "            pdf.cell(20, 4, txt=info, ln=1, align='L')\n",
    "        pdf.output(pdf_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "044ce079",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input the ingredients you choosed, separated by ',': chicken\n",
      "Is your the list ready? please confirm (Yes/No): yes\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Javier\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "RECIPE No 1 - ['Chicken Vesuvio']\n",
      "-------------\n",
      "\n",
      " - Existing Ingredients       :  chicken\n",
      " - Missing Ingredients ( 3 )  :  bacon, rinds, Banyuls\n",
      " - Cooking Time (minutes)     :  60.0\n",
      " - Recipe Calories (1 portion):  [4228.0430582]\n",
      " - Cooking Instructions       :  ['http://www.seriouseats.com/recipes/2011/12/chicken-vesuvio-recipe.html']\n",
      "\n",
      " GROCERY LIST\n",
      "\n",
      " 1.BACON\n",
      "Dry-cured Back Bacon, Unsmoked, Organic, Helen Browning (184g)      £5.20\n",
      "Unsmoked Streaky Bacon, Organic, Helen Browning (184g)      £5.00\n",
      "\n",
      " 2.RINDS\n",
      "Taleggio DOP, Organic (200g)      £4.95\n",
      "Rhiannon, Organic, Caws Cenarth (200g)      £7.50\n",
      "\n",
      " 3.BANYULS\n",
      " Sorry, couldn't find this ingredient, please check and try again \n",
      " We tried in this 2 webpages: www.abelandcole.co.uk & www.dutchexpatshop.com\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Usual Supplier (unless different is indicated) is: https://www.abelandcole.co.uk\n",
      "Considerations for usual Supplier: \n",
      "      - Price without taxes \n",
      "      - if there is a 2nd price detailed consider as \"offert\"\n",
      "================================================================================\n",
      "Would you like to create a '.pdf' file with this info? (Yes/No):no\n",
      "NO FILE WAS CREATED, HAVE A NICE DAY!\n",
      "================================================================================\n",
      "\n",
      "\n",
      "RECIPE No 2 - ['Chicken Paprikash']\n",
      "-------------\n",
      "\n",
      " - Existing Ingredients       :  chicken\n",
      " - Missing Ingredients ( 2 )  :  canola oil, square wonton wrappers\n",
      " - Cooking Time (minutes)     :  0.0\n",
      " - Recipe Calories (1 portion):  [3033.20125]\n",
      " - Cooking Instructions       :  ['http://norecipes.com/recipe/chicken-paprikash/']\n",
      "\n",
      " GROCERY LIST\n",
      "\n",
      " 1.CANOLA OIL\n",
      "Real Cola, Organic, Gusto Drinks (4 x 275ml)      £6.95\n",
      "\n",
      " 2.SQUARE WONTON WRAPPERS\n",
      "Big Cat Stout, Organic, Stroud Brewery (440ml)      £3.25\n",
      "Soap Bar, Hemp Almond Scented, Organic, Dr Bronner's (140g)      £5.65\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Usual Supplier (unless different is indicated) is: https://www.abelandcole.co.uk\n",
      "Considerations for usual Supplier: \n",
      "      - Price without taxes \n",
      "      - if there is a 2nd price detailed consider as \"offert\"\n",
      "================================================================================\n",
      "Would you like to create a '.pdf' file with this info? (Yes/No):no\n",
      "NO FILE WAS CREATED, HAVE A NICE DAY!\n",
      "================================================================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'unique'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13772\\2306975490.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# list_of_ingredients = ['lettuCE', 'mayonnaise', 'Carrot', 'AlfajOR', 'WGETHTyy']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mget_existing_ingredients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13772\\4081129215.py\u001b[0m in \u001b[0;36mget_existing_ingredients\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mlist_confirmation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist_confirmation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlist_confirmation\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"yes\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlist_confirmation\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"y\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mget_recipes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mingredients\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mget_existing_ingredients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13772\\4081129215.py\u001b[0m in \u001b[0;36mget_recipes\u001b[1;34m(ingredients)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;31m#     Here is were we set 3 recipes from 9 as feeedback (the 3 most shorter)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mshorter_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshorter_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0mget_ingredient_detail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshorter_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclean_recipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mingredients\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13772\\4081129215.py\u001b[0m in \u001b[0;36mget_ingredient_detail\u001b[1;34m(shorter_list, clean_recipe, ingredients)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RECIPE No\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mclean_recipe\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'recipe.label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'- Existing Ingredients       : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mingredients\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'unique'"
     ]
    }
   ],
   "source": [
    "# list_of_ingredients = ['lettuCE', 'mayonnaise', 'Carrot', 'AlfajOR', 'WGETHTyy']\n",
    "\n",
    "get_existing_ingredients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6626cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a02afa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
