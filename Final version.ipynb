{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79ac7916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from fpdf import FPDF\n",
    "from contextlib import redirect_stdout\n",
    "# from reportlab.pdfgen.canvas import Canvas\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#remove the measurements\n",
    "import unicodedata\n",
    "unicodedata.numeric(u'⅕')\n",
    "unicodedata.name(u'⅕')\n",
    "import spacy\n",
    "import re\n",
    "# pip install spacy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9dfa3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting coding\n",
    "\n",
    "# 1st function - User inputs the ingredients he has (or wants to use)\n",
    "def get_existing_ingredients():\n",
    "    ingredients = input(\"Input the ingredients you choosed, separated by ',': \")\n",
    "    list_confirmation = input('Is your the list ready? please confirm (Yes/No): ')\n",
    "    print('\\n')\n",
    "    list_confirmation = list_confirmation.lower()\n",
    "    if list_confirmation == \"yes\" or list_confirmation == \"y\":\n",
    "        get_recipes(ingredients)\n",
    "    else:\n",
    "        get_existing_ingredients()\n",
    "\n",
    "\n",
    "# 2nd step - Code will search at the url the recipes containing the inputted ingredients\n",
    "def get_recipes(ingredients):\n",
    "    url = \"https://edamam-recipe-search.p.rapidapi.com/search\"\n",
    "    querystring = {\"q\":ingredients}\n",
    "    headers = {\n",
    "    \"X-RapidAPI-Key\": \"636e6bafbemsh4d60f9770bbe76cp1e897ejsn1e8e8c2c9a8c\",\n",
    "    \"X-RapidAPI-Host\": \"edamam-recipe-search.p.rapidapi.com\"\n",
    "    }\n",
    "    \n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "\n",
    "    #data is always given for a total of 10 recipes\n",
    "    recipe_data = pd.json_normalize(response.json()['hits'])\n",
    "    recipe_data1 = recipe_data.rename(columns={'recipe.ingredientLines' : 'ingridient'})\n",
    "\n",
    "    #Put each ingredient in a row, duplicating the recipe rows\n",
    "    df = recipe_data1.explode('ingridient')\n",
    "\n",
    "    #splits the words, tokenizes them and assigns them a role, then a search is made for the searched roles\n",
    "    base_model = spacy.load('en_core_web_sm')\n",
    "\n",
    "    measurements = re.compile(r'(sliced|Sliced|halves|Halves|quart|pure|raw|unsweetened|Flaky|extra|Extra|fresh|fresh|juice|Juice|clear|½|weight|Small|small|tub|Tablespoon|lb|homemade|bowl|g|C|Tablespoons|1|2|3|4|5|6|7|8|9|0|medium|Medium|¼|Extra Virgin|slices|kg|100ml|200m|qts|lqts|lbs|tsp|tbs|Tbs|tbsp|bulb|cube|clove|cup|drop|ounce|oz|pinch|pound|teaspoon|large|grams|whole|tablespoon)s?')\n",
    "    extracted = []\n",
    "\n",
    "    for ix, row in df.iterrows():\n",
    "    #     print('\\r', \"Extracting ingredient for row\", ix, end='')\n",
    "        tokens = base_model(row['ingridient'])\n",
    "        extract = ''\n",
    "        for token in tokens:\n",
    "            if (token.dep_ in ['nsubj', 'ROOT']) and (token.pos_ in ['NOUN', 'PROPN']) and (not measurements.match(token.text)):\n",
    "            #explore children\n",
    "                for child in token.children:\n",
    "                    if (not measurements.match(child.text)) and (child.dep_ in ['amod', 'compound']):\n",
    "                        extract += child.text + ' '\n",
    "                extract += token.text + ' '\n",
    "        extracted.append(extract) \n",
    "\n",
    "    extracted_clean = []\n",
    "\n",
    "    for item in extracted:\n",
    "        item1 = item.strip()    \n",
    "        extracted_clean.append(item1)\n",
    "\n",
    "    #convert to dataframe to view and cleaning info\n",
    "    clean_recipe = df[['recipe.label', 'recipe.url', 'recipe.healthLabels', 'recipe.calories', 'recipe.totalTime','recipe.mealType']]\n",
    "    clean_recipe['ingredient'] = extracted_clean\n",
    "    nan_value = float(\"NaN\")\n",
    "    clean_recipe.replace(\"\", nan_value, inplace=True)\n",
    "    clean_recipe.dropna(subset = [\"ingredient\"], inplace=True)\n",
    " \n",
    "   \n",
    "    # Let's show only the shorter recipes (less ingredients missing) and sort by smaller\n",
    "    shorter_dict = {}\n",
    "    for x in range(0,9):\n",
    "        clean_recipe_x = clean_recipe.loc[x]\n",
    "        list_recipe_x = list(clean_recipe_x['ingredient'])\n",
    "        shorter_dict[x] = len(list_recipe_x)\n",
    "    shorter_dict = (dict(sorted(shorter_dict.items(), key=lambda item: item[1])))\n",
    "    shorter_list = list(shorter_dict.keys())\n",
    "    \n",
    "    #     Here is were we set 3 recipes from 9 as feeedback (the 3 most shorter)\n",
    "    shorter_list = shorter_list[0:3]\n",
    "    get_ingredient_detail(shorter_list, clean_recipe, ingredients)\n",
    "\n",
    "    \n",
    "# 3rd step - At this point we have the initial ingredients and the recipes including them\n",
    "# On this step we will call the function that does web-scrapping of the missing ingredients\n",
    "def get_ingredient_detail(shorter_list, clean_recipe, ingredients):\n",
    "    for x in range(0,3):\n",
    "        clean_recipe_x = clean_recipe.loc[shorter_list[x]]\n",
    "        list_recipe_x = list(clean_recipe_x['ingredient'])\n",
    "        print('\\n')\n",
    "        print(\"RECIPE No\",x+1,'-', (clean_recipe ['recipe.label'][x]).unique())\n",
    "        print('-------------')\n",
    "        print('\\n','- Existing Ingredients       : ', ingredients) \n",
    "        print(' - Missing Ingredients (',len(list_recipe_x),')  : ', (', '.join(list_recipe_x)))\n",
    "        print(' - Cooking Time (minutes)     : ', (clean_recipe ['recipe.totalTime'][x]).mean())\n",
    "        print(' - Recipe Calories (1 portion): ', (clean_recipe ['recipe.calories'][x]).unique())\n",
    "        print(' - Cooking Instructions       : ', (clean_recipe ['recipe.url'][x]).unique())\n",
    "        missing_ingredients(list_recipe_x)\n",
    "        you_want_copy(list_recipe_x, x, clean_recipe, ingredients)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06b26a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4rd step - This is the function that web-scrap the missing ingredients and show results\n",
    "def missing_ingredients(list_of_ingredients):\n",
    "    list_of_ingredients = [item.lower() for item in list_of_ingredients]\n",
    "    order = 0\n",
    "    print('\\n', 'GROCERY LIST')\n",
    "    for ingredient in list_of_ingredients:\n",
    "        \n",
    "        #         Initializating variables\n",
    "        order = order+1\n",
    "        url = \"https://www.abelandcole.co.uk/shop/search?term=\"+ingredient+\"&searchCat=products\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content)\n",
    "\n",
    "        #         Searching for ingredient name at the web\n",
    "        name_search = soup.find_all(\"div\", attrs={'class':'product-title'}) \n",
    "        name = [(option.text).replace('\\n', '') for option in name_search]\n",
    "\n",
    "        #         Searching for ingredient price at the web\n",
    "        price_search = soup.find_all(\"div\", attrs={'class':'product-price'})\n",
    "        price = [(option.text).replace('\\n', '').replace('\\r', '').replace(' ', '').replace('£', '    £') for option in price_search]\n",
    "\n",
    "        final_list = []\n",
    "        \n",
    "        #         Appending name+price as single list element\n",
    "        for i in range(len(name)):\n",
    "            final_list.append(name[i]+' '+price[i])\n",
    "\n",
    "        #         Showing results or error message\n",
    "        if not final_list:\n",
    "            print('\\n', str(order)+\".\"+ingredient.upper())\n",
    "            \n",
    "        #             Calling the 2nd function to search \n",
    "            single_ingredient(ingredient)\n",
    "        else:\n",
    "            print('\\n', str(order)+\".\"+ingredient.upper())\n",
    "            print('\\n'.join(final_list[:2]))\n",
    "    \n",
    "    print('\\n')\n",
    "    print('================================================================================')\n",
    "    print('Usual Supplier (unless different is indicated) is: https://www.abelandcole.co.uk')\n",
    "    print('Considerations for usual Supplier:','\\n','     - Price without taxes','\\n','     - if there is a 2nd price detailed consider as \"offert\"')\n",
    "\n",
    "\n",
    "# 5th step - on each recipe iteration (where we search missing ingredientes) code asks user if wants a .pdf copy\n",
    "def you_want_copy(list_recipe_x, x, clean_recipe, ingredients):    \n",
    "    #     Checking if user wants a copy file with info\n",
    "    print('================================================================================')\n",
    "    create_file = input(\"Would you like to create a '.pdf' file with this info? (Yes/No):\")\n",
    "    create_file = create_file.lower()\n",
    "    if create_file == \"yes\" or create_file == \"y\":\n",
    "        print(\"Preparing '.pdf' file..............\")\n",
    "        create_results_files(list_recipe_x, x, clean_recipe, ingredients)\n",
    "        txt_file_name = str(x+1)+'.txt'\n",
    "        os.remove(txt_file_name)\n",
    "        print('YOUR FILE IS READY, HAVE A NICE DAY!')\n",
    "        print('================================================================================')\n",
    "    else:\n",
    "        print('NO FILE WAS CREATED, HAVE A NICE DAY!')\n",
    "        print('================================================================================')\n",
    "\n",
    "        \n",
    "\n",
    "# This is a sub-function from step 4, doing web-scrapping in a 2nd webpage \n",
    "# just in case 1st one doesn't include the ingredient    \n",
    "def single_ingredient(ingredient):\n",
    "    ingredient = ingredient.lower()\n",
    "    url = \"https://www.dutchexpatshop.com/en/catalogsearch/result/?q=\"+ingredient\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content)\n",
    "    \n",
    "    search = soup.find_all(\"div\", attrs={'class':'product-item-info'})\n",
    "    list = [option.text for option in search]\n",
    "    list1 = [info.replace('        Add to Cart ', '') for info in list]\n",
    "    \n",
    "    if not list1:\n",
    "        print(\" Sorry, couldn't find this ingredient, please check and try again\",'\\n', \"We tried in this 2 webpages: www.abelandcole.co.uk & www.dutchexpatshop.com\")\n",
    "    else:\n",
    "        print('\\n'.join(list1[:2]))\n",
    "        print(\"** This specific product was found at: www.dutchexpatshop.com - Price with and without tax\")   \n",
    "\n",
    "        \n",
    "# This is a sub-function from step 5, if users do wants a .pdf copy of the recipe\n",
    "# The code will create a .txt file first and then will convert to .pdf (erasing original .txt)      \n",
    "def create_results_files(list_recipe_x, x, clean_recipe, ingredients):\n",
    "    # 1st create the txt result file     \n",
    "    txt_file_name = str(x+1)+'.txt'\n",
    "    with open(txt_file_name, 'w') as file:\n",
    "        with redirect_stdout(file):\n",
    "            output = print(\"RECIPE No\",x+1,'-', (clean_recipe ['recipe.label'][x]).unique())\n",
    "            output = print('-------------')\n",
    "            output = print('\\n','- Existing Ingredients       : ', ingredients)\n",
    "            output = print(' - Missing Ingredients (',len(list_recipe_x),')  : ', (', '.join(list_recipe_x))) \n",
    "            output = print(' - Cooking Time (minutes)     : ', (clean_recipe ['recipe.totalTime'][x]).mean())\n",
    "            output = print(' - Recipe Calories (1 portion): ', (clean_recipe ['recipe.calories'][x]).unique())\n",
    "            output = print(' - Cooking Instructions       : ', (clean_recipe ['recipe.url'][x]).unique())\n",
    "            output = str(missing_ingredients(list_recipe_x))    \n",
    "    \n",
    "    # 2nd convert txt result file into pdf  \n",
    "    pdf_file_name = str(x+1)+'.pdf'\n",
    "    with open(txt_file_name,'rb') as research:\n",
    "        pdf = FPDF()\n",
    "        pdf.add_page()\n",
    "        pdf.set_font('arial', size=10)\n",
    "        for line in research:\n",
    "            info = line.decode('latin-1')\n",
    "            pdf.cell(20, 4, txt=info, ln=1, align='L')\n",
    "        pdf.output(pdf_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "044ce079",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# list_of_ingredients = ['lettuCE', 'mayonnaise', 'Carrot', 'AlfajOR', 'WGETHTyy']\n",
    "\n",
    "get_existing_ingredients()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
